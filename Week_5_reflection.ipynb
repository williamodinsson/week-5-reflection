{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Based on a word network, write a program that takes a sentence and exchanges each word to\n",
        "another one with a similar meaning, if one exists. You are free to exclude stop words and names\n",
        "from this transformation.\n",
        "Please include a code snippet and at least three example inputs with their respective outputs\n",
        "in your response.\n",
        "Discuss how legible (in the sense of easy to understand) you find the transformed texts in\n",
        "comparison to the originals."
      ],
      "metadata": {
        "id": "gO5Koz1tn08Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgMkEPPKh1hq",
        "outputId": "6a0182e9-7359-49a6-bc16-02f6745f7da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk # this we already have\n",
        "nltk.download('wordnet') # this is new, download once per environment\n",
        "nltk.download('omw-1.4') # same here\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'A conditional distribution is a distribution of values for one variable that exists when you specify the values of other variables.'"
      ],
      "metadata": {
        "id": "xdHuCiSfiRBm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'The Riemann integral, created by Bernhard Riemann, was the first rigorous definition of the integral of a function on an interval.'"
      ],
      "metadata": {
        "id": "wKr4KU-_ppMi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = 'A σ-algebra, also known as the σ-field,  on a set X is a nonempty collection sigma of subsets of X closed under complement, countable unions, and countable intersections.'"
      ],
      "metadata": {
        "id": "clM6AVaVpo61"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "word_tokens = word_tokenize(text)\n",
        "\n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "filtered_sentence = [word.lower() for word in filtered_sentence if word.isalpha()]\n",
        "\n",
        "print(word_tokens)\n",
        "print(filtered_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvsBxTNkjlsn",
        "outputId": "9a11ed06-922e-4759-b4d4-70b4e642b0da"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'conditional', 'distribution', 'is', 'a', 'distribution', 'of', 'values', 'for', 'one', 'variable', 'that', 'exists', 'when', 'you', 'specify', 'the', 'values', 'of', 'other', 'variables', '.']\n",
            "['conditional', 'distribution', 'distribution', 'values', 'one', 'variable', 'exists', 'specify', 'values', 'variables']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = ' '.join(filtered_sentence)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "hyVu_hNp9R6U",
        "outputId": "18c0eb98-a3b9-4851-ac80-31b10791e01e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'conditional distribution distribution values one variable exists specify values variables'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = []\n",
        "for w in t1.split():\n",
        "  ss = wn.synsets(w)\n",
        "  # print(ss[:1])\n",
        "  for s in ss[:1]:\n",
        "    n1.append(s.lemma_names()[0])\n",
        "\n",
        "n1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBIC8RtptJ1a",
        "outputId": "ef144ea8-2666-474f-83a9-224b76ec77d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['conditional',\n",
              " 'distribution',\n",
              " 'distribution',\n",
              " 'values',\n",
              " 'one',\n",
              " 'variable',\n",
              " 'exist',\n",
              " 'stipulate',\n",
              " 'values',\n",
              " 'variable']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens1 = word_tokenize(text1)\n",
        "\n",
        "filtered_sentence1 = [w for w in word_tokens1 if not w.lower() in stop_words]\n",
        "filtered_sentence1 = [word.lower() for word in filtered_sentence1 if word.isalpha()]\n",
        "Names = ['Riemann', 'Bernhard', 'riemann', 'bernhard']\n",
        "n_word_tokens1 = []\n",
        "for i in word_tokens1:\n",
        "  if i not in Names:\n",
        "    n_word_tokens1.append(i)\n",
        "\n",
        "n_filtered_sentences1 = []\n",
        "for i in filtered_sentence1:\n",
        "  if i not in Names:\n",
        "    n_filtered_sentences1.append(i)\n",
        "\n",
        "print(word_tokens1)\n",
        "print(filtered_sentence1)\n",
        "print('\\n')\n",
        "print(n_word_tokens1)\n",
        "print(n_filtered_sentences1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Zn60NqjkzS",
        "outputId": "893ec056-369d-419c-d5f1-815ec9cb455f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Riemann', 'integral', ',', 'created', 'by', 'Bernhard', 'Riemann', ',', 'was', 'the', 'first', 'rigorous', 'definition', 'of', 'the', 'integral', 'of', 'a', 'function', 'on', 'an', 'interval', '.']\n",
            "['riemann', 'integral', 'created', 'bernhard', 'riemann', 'first', 'rigorous', 'definition', 'integral', 'function', 'interval']\n",
            "\n",
            "\n",
            "['The', 'integral', ',', 'created', 'by', ',', 'was', 'the', 'first', 'rigorous', 'definition', 'of', 'the', 'integral', 'of', 'a', 'function', 'on', 'an', 'interval', '.']\n",
            "['integral', 'created', 'first', 'rigorous', 'definition', 'integral', 'function', 'interval']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = ' '.join(n_filtered_sentences1)\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "LiSI8eKL-BJB",
        "outputId": "852cdddb-5cd3-4fa5-f854-233596a7db43"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'integral created first rigorous definition integral function interval'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n2 = []\n",
        "for w in t2.split():\n",
        "  ss1 = wn.synsets(w)\n",
        "  \n",
        "  for s in ss1[:1]:\n",
        "    n2.append(s.lemma_names()[0])\n",
        "\n",
        "n2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qidfdYmd_CO5",
        "outputId": "eb7e26b4-00cd-4d9b-c594-6fe8d06afbd2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['integral',\n",
              " 'make',\n",
              " 'first',\n",
              " 'rigorous',\n",
              " 'definition',\n",
              " 'integral',\n",
              " 'function',\n",
              " 'time_interval']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens2 = word_tokenize(text2)\n",
        "\n",
        "filtered_sentence2 = [w for w in word_tokens2 if not w.lower() in stop_words]\n",
        "filtered_sentence2 = [word.lower() for word in filtered_sentence2 if word.isalpha()]\n",
        "\n",
        "\n",
        "print(word_tokens2)\n",
        "print(filtered_sentence2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzSsrQmis_9w",
        "outputId": "2851b2fd-698b-4f21-b2fe-75a285c00cba"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'σ-algebra', ',', 'also', 'known', 'as', 'the', 'σ-field', ',', 'on', 'a', 'set', 'X', 'is', 'a', 'nonempty', 'collection', 'sigma', 'of', 'subsets', 'of', 'X', 'closed', 'under', 'complement', ',', 'countable', 'unions', ',', 'and', 'countable', 'intersections', '.']\n",
            "['also', 'known', 'set', 'x', 'nonempty', 'collection', 'sigma', 'subsets', 'x', 'closed', 'complement', 'countable', 'unions', 'countable', 'intersections']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = ' '.join(filtered_sentence2)\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "oS_KqE5It0am",
        "outputId": "651afcc4-439d-4f9d-aff4-767ed166f9e0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'also known set x nonempty collection sigma subsets x closed complement countable unions countable intersections'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n3 = []\n",
        "for w in t3.split():\n",
        "  ss2 = wn.synsets(w)\n",
        "  \n",
        "  for s in ss2[:1]:\n",
        "    n3.append(s.lemma_names()[0])\n",
        "\n",
        "n3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLkcuvg2APMt",
        "outputId": "36b4f6a4-99be-4896-a86b-68f4a93cec4d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['besides',\n",
              " 'know',\n",
              " 'set',\n",
              " 'ten',\n",
              " 'collection',\n",
              " 'sigma',\n",
              " 'subset',\n",
              " 'ten',\n",
              " 'close',\n",
              " 'complement',\n",
              " 'countable',\n",
              " 'union',\n",
              " 'countable',\n",
              " 'intersection']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_parser_synonym_antonym_finder(text:str):\n",
        "     from nltk.tokenize import word_tokenize\n",
        "     from nltk.corpus import wordnet\n",
        "     from collections import defaultdict\n",
        "     import pprint\n",
        "\n",
        "     tokens = word_tokenize(text)\n",
        "     synonyms = defaultdict(list)\n",
        "     antonyms = defaultdict(list)\n",
        "     for token in tokens:\n",
        "          for syn in wordnet.synsets(token):\n",
        "               for i in syn.lemmas():\n",
        "                    #synonyms.append(i.name())\n",
        "                    #print(f'{token} synonyms are: {i.name()}')\n",
        "                    synonyms[token].append(i.name())\n",
        "                    if i.antonyms():\n",
        "                         #antonyms.append(i.antonyms()[0].name())\n",
        "                         #print(f'{token} antonyms are: {i.antonyms()[0].name()}')\n",
        "                         antonyms[token].append(i.antonyms()[0].name())\n",
        "     print('Synonyms: \\n')\n",
        "     pprint.pprint(dict(synonyms))\n",
        "     print('----------------------------------------------------------------\\n')\n",
        "     print('Antonyms: \\n')\n",
        "     pprint.pprint(dict(antonyms))\n",
        "     synonym_output = pprint.pformat((dict(synonyms)))\n",
        "     antonyms_output = pprint.pformat((dict(antonyms)))\n",
        "     with open(str(text[:5]) + \".txt\", \"a\") as f:\n",
        "          f.write(\"Starting of Synonyms of the Words from the Sentences: \" + synonym_output + \"\\n\")\n",
        "          f.write(\"Starting of Antonyms of the Words from the Sentences: \" + antonyms_output + \"\\n\")\n",
        "          f.close()"
      ],
      "metadata": {
        "id": "xYZBvibuizyM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = text_parser_synonym_antonym_finder(t1)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoEZhuvijIGz",
        "outputId": "bfc14cc3-0f16-4cce-d42e-40e9754923ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms: \n",
            "\n",
            "{'conditional': ['conditional', 'conditional'],\n",
            " 'distribution': ['distribution',\n",
            "                  'statistical_distribution',\n",
            "                  'distribution',\n",
            "                  'dispersion',\n",
            "                  'distribution',\n",
            "                  'distribution',\n",
            "                  'distribution',\n",
            "                  'statistical_distribution',\n",
            "                  'distribution',\n",
            "                  'dispersion',\n",
            "                  'distribution',\n",
            "                  'distribution'],\n",
            " 'exists': ['exist', 'be', 'exist', 'survive', 'live', 'subsist'],\n",
            " 'one': ['one',\n",
            "         '1',\n",
            "         'I',\n",
            "         'ace',\n",
            "         'single',\n",
            "         'unity',\n",
            "         'one',\n",
            "         'one',\n",
            "         '1',\n",
            "         'i',\n",
            "         'ane',\n",
            "         'one',\n",
            "         'unitary',\n",
            "         'one',\n",
            "         'one',\n",
            "         'one',\n",
            "         'one',\n",
            "         'matchless',\n",
            "         'nonpareil',\n",
            "         'one',\n",
            "         'one_and_only',\n",
            "         'peerless',\n",
            "         'unmatched',\n",
            "         'unmatchable',\n",
            "         'unrivaled',\n",
            "         'unrivalled'],\n",
            " 'specify': ['stipulate',\n",
            "             'qualify',\n",
            "             'condition',\n",
            "             'specify',\n",
            "             'specify',\n",
            "             'set',\n",
            "             'determine',\n",
            "             'define',\n",
            "             'fix',\n",
            "             'limit',\n",
            "             'specify',\n",
            "             'define',\n",
            "             'delineate',\n",
            "             'delimit',\n",
            "             'delimitate',\n",
            "             'specify',\n",
            "             'particularize',\n",
            "             'particularise',\n",
            "             'specialize',\n",
            "             'specialise',\n",
            "             'pin_down',\n",
            "             'peg_down',\n",
            "             'nail_down',\n",
            "             'narrow_down',\n",
            "             'narrow',\n",
            "             'specify',\n",
            "             'intend',\n",
            "             'destine',\n",
            "             'designate',\n",
            "             'specify',\n",
            "             'assign',\n",
            "             'specify',\n",
            "             'set_apart'],\n",
            " 'values': ['values',\n",
            "            'value',\n",
            "            'value',\n",
            "            'value',\n",
            "            'economic_value',\n",
            "            'value',\n",
            "            'value',\n",
            "            'time_value',\n",
            "            'note_value',\n",
            "            'value',\n",
            "            'value',\n",
            "            'prize',\n",
            "            'value',\n",
            "            'treasure',\n",
            "            'appreciate',\n",
            "            'respect',\n",
            "            'esteem',\n",
            "            'value',\n",
            "            'prize',\n",
            "            'prise',\n",
            "            'measure',\n",
            "            'evaluate',\n",
            "            'valuate',\n",
            "            'assess',\n",
            "            'appraise',\n",
            "            'value',\n",
            "            'rate',\n",
            "            'value',\n",
            "            'values',\n",
            "            'value',\n",
            "            'value',\n",
            "            'value',\n",
            "            'economic_value',\n",
            "            'value',\n",
            "            'value',\n",
            "            'time_value',\n",
            "            'note_value',\n",
            "            'value',\n",
            "            'value',\n",
            "            'prize',\n",
            "            'value',\n",
            "            'treasure',\n",
            "            'appreciate',\n",
            "            'respect',\n",
            "            'esteem',\n",
            "            'value',\n",
            "            'prize',\n",
            "            'prise',\n",
            "            'measure',\n",
            "            'evaluate',\n",
            "            'valuate',\n",
            "            'assess',\n",
            "            'appraise',\n",
            "            'value',\n",
            "            'rate',\n",
            "            'value'],\n",
            " 'variable': ['variable',\n",
            "              'variable',\n",
            "              'variable_quantity',\n",
            "              'variable_star',\n",
            "              'variable',\n",
            "              'variable',\n",
            "              'variable',\n",
            "              'varying',\n",
            "              'variable',\n",
            "              'variable'],\n",
            " 'variables': ['variable',\n",
            "               'variable',\n",
            "               'variable_quantity',\n",
            "               'variable_star',\n",
            "               'variable',\n",
            "               'variable']}\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Antonyms: \n",
            "\n",
            "{'conditional': ['unconditional'],\n",
            " 'distribution': ['concentration', 'concentration'],\n",
            " 'specify': ['generalize'],\n",
            " 'values': ['disrespect', 'disesteem', 'disrespect', 'disesteem'],\n",
            " 'variable': ['invariable']}\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = text_parser_synonym_antonym_finder(t2)\n",
        "\n",
        "print(result1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btkYfL2lsI_a",
        "outputId": "41f7a88c-197a-4fcb-f02b-863123d80203"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms: \n",
            "\n",
            "{'created': ['make',\n",
            "             'create',\n",
            "             'create',\n",
            "             'create',\n",
            "             'create',\n",
            "             'create',\n",
            "             'make',\n",
            "             'produce',\n",
            "             'make',\n",
            "             'create'],\n",
            " 'definition': ['definition', 'definition'],\n",
            " 'first': ['first',\n",
            "           'number_one',\n",
            "           'first',\n",
            "           'number_one',\n",
            "           'number_1',\n",
            "           'beginning',\n",
            "           'commencement',\n",
            "           'first',\n",
            "           'outset',\n",
            "           'get-go',\n",
            "           'start',\n",
            "           'kickoff',\n",
            "           'starting_time',\n",
            "           'showtime',\n",
            "           'offset',\n",
            "           'first_base',\n",
            "           'first',\n",
            "           'first',\n",
            "           'first-class_honours_degree',\n",
            "           'first_gear',\n",
            "           'first',\n",
            "           'low_gear',\n",
            "           'low',\n",
            "           'first',\n",
            "           'first',\n",
            "           '1st',\n",
            "           'inaugural',\n",
            "           'initiative',\n",
            "           'initiatory',\n",
            "           'first',\n",
            "           'maiden',\n",
            "           'beginning',\n",
            "           'first',\n",
            "           'first',\n",
            "           'foremost',\n",
            "           'world-class',\n",
            "           'first',\n",
            "           'first',\n",
            "           'firstly',\n",
            "           'foremost',\n",
            "           'first_of_all',\n",
            "           'first_off',\n",
            "           'first',\n",
            "           'for_the_first_time',\n",
            "           'first',\n",
            "           'foremost',\n",
            "           'first'],\n",
            " 'function': ['function',\n",
            "              'mathematical_function',\n",
            "              'single-valued_function',\n",
            "              'map',\n",
            "              'mapping',\n",
            "              'function',\n",
            "              'purpose',\n",
            "              'role',\n",
            "              'use',\n",
            "              'function',\n",
            "              'office',\n",
            "              'part',\n",
            "              'role',\n",
            "              'function',\n",
            "              'function',\n",
            "              'affair',\n",
            "              'occasion',\n",
            "              'social_occasion',\n",
            "              'function',\n",
            "              'social_function',\n",
            "              'routine',\n",
            "              'subroutine',\n",
            "              'subprogram',\n",
            "              'procedure',\n",
            "              'function',\n",
            "              'function',\n",
            "              'work',\n",
            "              'operate',\n",
            "              'go',\n",
            "              'run',\n",
            "              'serve',\n",
            "              'function',\n",
            "              'officiate',\n",
            "              'function'],\n",
            " 'integral': ['integral',\n",
            "              'built-in',\n",
            "              'constitutional',\n",
            "              'inbuilt',\n",
            "              'inherent',\n",
            "              'integral',\n",
            "              'integral',\n",
            "              'entire',\n",
            "              'intact',\n",
            "              'integral',\n",
            "              'integral',\n",
            "              'built-in',\n",
            "              'constitutional',\n",
            "              'inbuilt',\n",
            "              'inherent',\n",
            "              'integral',\n",
            "              'integral',\n",
            "              'entire',\n",
            "              'intact',\n",
            "              'integral'],\n",
            " 'interval': ['time_interval',\n",
            "              'interval',\n",
            "              'interval',\n",
            "              'interval',\n",
            "              'separation',\n",
            "              'interval',\n",
            "              'musical_interval'],\n",
            " 'rigorous': ['rigorous', 'strict', 'rigorous', 'stringent', 'tight']}\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Antonyms: \n",
            "\n",
            "{'first': ['middle', 'last', 'second'], 'function': ['malfunction']}\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = text_parser_synonym_antonym_finder(t3)\n",
        "\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64TYWwSBuK7H",
        "outputId": "9f254130-c179-40f2-dc7a-2215f0c8154d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms: \n",
            "\n",
            "{'also': ['besides', 'too', 'also', 'likewise', 'as_well'],\n",
            " 'closed': ['close',\n",
            "            'shut',\n",
            "            'close',\n",
            "            'shut',\n",
            "            'close_up',\n",
            "            'close',\n",
            "            'fold',\n",
            "            'shut_down',\n",
            "            'close_down',\n",
            "            'close',\n",
            "            'conclude',\n",
            "            'close',\n",
            "            'close',\n",
            "            'close',\n",
            "            'close',\n",
            "            'close',\n",
            "            'close',\n",
            "            'close',\n",
            "            'come_together',\n",
            "            'close',\n",
            "            'close',\n",
            "            'close',\n",
            "            'close',\n",
            "            'fill_up',\n",
            "            'close_up',\n",
            "            'close',\n",
            "            'close',\n",
            "            'closed',\n",
            "            'closed',\n",
            "            'shut',\n",
            "            'unopen',\n",
            "            'closed',\n",
            "            'closed',\n",
            "            'shut',\n",
            "            'closed',\n",
            "            'closed',\n",
            "            'closed',\n",
            "            'closed',\n",
            "            'unsympathetic',\n",
            "            'closed',\n",
            "            'closed_in'],\n",
            " 'collection': ['collection',\n",
            "                'aggregation',\n",
            "                'accumulation',\n",
            "                'assemblage',\n",
            "                'collection',\n",
            "                'compendium',\n",
            "                'solicitation',\n",
            "                'appeal',\n",
            "                'collection',\n",
            "                'ingathering',\n",
            "                'collection',\n",
            "                'collecting',\n",
            "                'assembling',\n",
            "                'aggregation'],\n",
            " 'complement': ['complement',\n",
            "                'complement',\n",
            "                'complement',\n",
            "                'full_complement',\n",
            "                'complement',\n",
            "                'accompaniment',\n",
            "                'complement',\n",
            "                'complement',\n",
            "                'complement'],\n",
            " 'countable': ['countable',\n",
            "               'denumerable',\n",
            "               'enumerable',\n",
            "               'numerable',\n",
            "               'countable',\n",
            "               'denumerable',\n",
            "               'enumerable',\n",
            "               'numerable'],\n",
            " 'intersections': ['intersection',\n",
            "                   'intersection_point',\n",
            "                   'point_of_intersection',\n",
            "                   'intersection',\n",
            "                   'crossroad',\n",
            "                   'crossway',\n",
            "                   'crossing',\n",
            "                   'carrefour',\n",
            "                   'intersection',\n",
            "                   'intersection',\n",
            "                   'product',\n",
            "                   'Cartesian_product',\n",
            "                   'overlap',\n",
            "                   'convergence',\n",
            "                   'intersection',\n",
            "                   'intersection'],\n",
            " 'known': ['know',\n",
            "           'cognize',\n",
            "           'cognise',\n",
            "           'know',\n",
            "           'know',\n",
            "           'know',\n",
            "           'know',\n",
            "           'experience',\n",
            "           'live',\n",
            "           'acknowledge',\n",
            "           'recognize',\n",
            "           'recognise',\n",
            "           'know',\n",
            "           'know',\n",
            "           'sleep_together',\n",
            "           'roll_in_the_hay',\n",
            "           'love',\n",
            "           'make_out',\n",
            "           'make_love',\n",
            "           'sleep_with',\n",
            "           'get_laid',\n",
            "           'have_sex',\n",
            "           'know',\n",
            "           'do_it',\n",
            "           'be_intimate',\n",
            "           'have_intercourse',\n",
            "           'have_it_away',\n",
            "           'have_it_off',\n",
            "           'screw',\n",
            "           'fuck',\n",
            "           'jazz',\n",
            "           'eff',\n",
            "           'hump',\n",
            "           'lie_with',\n",
            "           'bed',\n",
            "           'have_a_go_at_it',\n",
            "           'bang',\n",
            "           'get_it_on',\n",
            "           'bonk',\n",
            "           'know',\n",
            "           'know',\n",
            "           'know',\n",
            "           'known'],\n",
            " 'set': ['set',\n",
            "         'set',\n",
            "         'set',\n",
            "         'exercise_set',\n",
            "         'stage_set',\n",
            "         'set',\n",
            "         'set',\n",
            "         'circle',\n",
            "         'band',\n",
            "         'lot',\n",
            "         'bent',\n",
            "         'set',\n",
            "         'set',\n",
            "         'set',\n",
            "         'hardening',\n",
            "         'solidifying',\n",
            "         'solidification',\n",
            "         'set',\n",
            "         'curing',\n",
            "         'Set',\n",
            "         'Seth',\n",
            "         'set',\n",
            "         'set',\n",
            "         'readiness',\n",
            "         'set',\n",
            "         'put',\n",
            "         'set',\n",
            "         'place',\n",
            "         'pose',\n",
            "         'position',\n",
            "         'lay',\n",
            "         'determine',\n",
            "         'set',\n",
            "         'specify',\n",
            "         'set',\n",
            "         'determine',\n",
            "         'define',\n",
            "         'fix',\n",
            "         'limit',\n",
            "         'set',\n",
            "         'mark',\n",
            "         'set',\n",
            "         'set',\n",
            "         'fix',\n",
            "         'prepare',\n",
            "         'set_up',\n",
            "         'ready',\n",
            "         'gear_up',\n",
            "         'set',\n",
            "         'set',\n",
            "         'set',\n",
            "         'localize',\n",
            "         'localise',\n",
            "         'place',\n",
            "         'set',\n",
            "         'go_down',\n",
            "         'go_under',\n",
            "         'arrange',\n",
            "         'set',\n",
            "         'plant',\n",
            "         'set',\n",
            "         'set',\n",
            "         'jell',\n",
            "         'set',\n",
            "         'congeal',\n",
            "         'typeset',\n",
            "         'set',\n",
            "         'set',\n",
            "         'set',\n",
            "         'countersink',\n",
            "         'set',\n",
            "         'sic',\n",
            "         'set',\n",
            "         'place',\n",
            "         'put',\n",
            "         'set',\n",
            "         'rig',\n",
            "         'set',\n",
            "         'set_up',\n",
            "         'set_up',\n",
            "         'lay_out',\n",
            "         'set',\n",
            "         'adjust',\n",
            "         'set',\n",
            "         'correct',\n",
            "         'fructify',\n",
            "         'set',\n",
            "         'dress',\n",
            "         'arrange',\n",
            "         'set',\n",
            "         'do',\n",
            "         'coif',\n",
            "         'coiffe',\n",
            "         'coiffure',\n",
            "         'fit',\n",
            "         'primed',\n",
            "         'set',\n",
            "         'fixed',\n",
            "         'set',\n",
            "         'rigid',\n",
            "         'located',\n",
            "         'placed',\n",
            "         'set',\n",
            "         'situated',\n",
            "         'laid',\n",
            "         'set',\n",
            "         'set',\n",
            "         'determined',\n",
            "         'dictated',\n",
            "         'set',\n",
            "         'hardened',\n",
            "         'set'],\n",
            " 'sigma': ['sigma'],\n",
            " 'subsets': ['subset'],\n",
            " 'unions': ['union',\n",
            "            'labor_union',\n",
            "            'trade_union',\n",
            "            'trades_union',\n",
            "            'brotherhood',\n",
            "            'Union',\n",
            "            'North',\n",
            "            'coupling',\n",
            "            'mating',\n",
            "            'pairing',\n",
            "            'conjugation',\n",
            "            'union',\n",
            "            'sexual_union',\n",
            "            'union',\n",
            "            'unification',\n",
            "            'marriage',\n",
            "            'matrimony',\n",
            "            'union',\n",
            "            'spousal_relationship',\n",
            "            'wedlock',\n",
            "            'union',\n",
            "            'conglutination',\n",
            "            'union',\n",
            "            'union',\n",
            "            'sum',\n",
            "            'join',\n",
            "            'union',\n",
            "            'union',\n",
            "            'union',\n",
            "            'unification',\n",
            "            'uniting',\n",
            "            'conjugation',\n",
            "            'jointure'],\n",
            " 'x': ['ten',\n",
            "       '10',\n",
            "       'X',\n",
            "       'tenner',\n",
            "       'decade',\n",
            "       'X',\n",
            "       'x',\n",
            "       'ex',\n",
            "       'Adam',\n",
            "       'ecstasy',\n",
            "       'XTC',\n",
            "       'go',\n",
            "       'disco_biscuit',\n",
            "       'cristal',\n",
            "       'X',\n",
            "       'hug_drug',\n",
            "       'ten',\n",
            "       '10',\n",
            "       'x',\n",
            "       'ten',\n",
            "       '10',\n",
            "       'X',\n",
            "       'tenner',\n",
            "       'decade',\n",
            "       'X',\n",
            "       'x',\n",
            "       'ex',\n",
            "       'Adam',\n",
            "       'ecstasy',\n",
            "       'XTC',\n",
            "       'go',\n",
            "       'disco_biscuit',\n",
            "       'cristal',\n",
            "       'X',\n",
            "       'hug_drug',\n",
            "       'ten',\n",
            "       '10',\n",
            "       'x']}\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Antonyms: \n",
            "\n",
            "{'closed': ['open',\n",
            "            'open',\n",
            "            'open',\n",
            "            'open',\n",
            "            'open',\n",
            "            'open',\n",
            "            'open',\n",
            "            'open',\n",
            "            'open'],\n",
            " 'known': ['ignore', 'unknown'],\n",
            " 'set': ['rise'],\n",
            " 'unions': ['separation', 'disunion']}\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, based on the response to the previous question: design a program that assigns a numerical\n",
        "similarity score to two input sentences in terms of how similar they are with respect to where\n",
        "the words are within the conceptual hierarchies in WordNet.\n",
        "Instead of using just unigram-level similarity, try to incorporate n-gram aspects of assigning a\n",
        "higher similarity to texts that contain sequences of words that are all similar to one another,\n",
        "lowering the similarity whenever this breaks.\n",
        "For example a small dog that is hungry is very similar to a petite canine who runs in the first\n",
        "four words but then differs at the end.\n",
        "Again, please provide a code snippet and examples (you can reuse the inputs and the outputs\n",
        "of the previous question as examples in this question)."
      ],
      "metadata": {
        "id": "h085ZBOFphLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "dsbeI2ENFWQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = []\n",
        "q2 = []\n",
        "q3 = []\n",
        "q1.append(text)\n",
        "q2.append(text1)\n",
        "q3.append(text2)"
      ],
      "metadata": {
        "id": "pPDAx9J2EtM1"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L12-v2')\n",
        "\n",
        "# Two lists of sentences\n",
        "sentences1 = q1\n",
        "sentences2 = n1\n",
        "sentences3 = q2\n",
        "sentences4 = n2\n",
        "sentences5 = q3\n",
        "sentences6 = n3\n",
        "\n",
        "#Compute embedding for both lists\n",
        "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
        "embeddings3 = model.encode(sentences3, convert_to_tensor=True)\n",
        "embeddings4 = model.encode(sentences4, convert_to_tensor=True)\n",
        "embeddings5 = model.encode(sentences5, convert_to_tensor=True)\n",
        "embeddings6 = model.encode(sentences6, convert_to_tensor=True)\n",
        "\n",
        "#Compute cosine-similarits\n",
        "cosine_scores1 = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
        "cosine_scores2 = util.pytorch_cos_sim(embeddings3, embeddings4)\n",
        "cosine_scores3 = util.pytorch_cos_sim(embeddings5, embeddings6)\n",
        "\n",
        "#Output the pairs with their score\n",
        "for i in range(len(sentences1)):\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores1[i][i]))\n",
        "for i in range(len(sentences3)):\n",
        "  print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences3[i], sentences4[i], cosine_scores2[i][i]))\n",
        "\n",
        "for i in range(len(sentences5)):\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences5[i], sentences6[i], cosine_scores3[i][i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NfWB6k_wSp2",
        "outputId": "2b403ad0-3667-4a1d-b379-f0d23e4cef4c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A conditional distribution is a distribution of values for one variable that exists when you specify the values of other variables. \t\t conditional \t\t Score: 0.4992\n",
            "The Riemann integral, created by Bernhard Riemann, was the first rigorous definition of the integral of a function on an interval. \t\t integral \t\t Score: 0.6989\n",
            "a sigma algebra, also known as the sigma field,  on a set X is a nonempty collection sigma of subsets of X closed under complement, countable unions, and countable intersections. \t\t besides \t\t Score: 0.0380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Open Multilingual Wordnet at https://github.com/globalwordnet/OMW, write a\n",
        "program that takes as input a sentence along with information about what language this sentence\n",
        "is written in and what language to translate it to, and then, using WordNet to map concepts,\n",
        "write a very rough automated translator.\n",
        "Provide a code snippet, input-output examples, and a discussion on the aspects of language\n",
        "translations that are hard or impossible to capture just using a WordNet as a knowledge base."
      ],
      "metadata": {
        "id": "GdkCRtRx0gJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Enter a sentence : ')\n",
        "out= input()\n",
        "print('Please select an available language code from eng, fra, arb, spa, swe, dan, cmn, tha, and jpn.')\n",
        "lan = input()\n",
        "word_tokenize(out)\n",
        "o = ' '.join([word.lower() for word in [w for w in word_tokenize(out) if not w.lower() in stop_words] if word.isalpha()])\n",
        "ttt1 = []\n",
        "for w in o.split():\n",
        "  i = wn.synsets(w)\n",
        "  \n",
        "  for s in i[:1]:\n",
        "    # print(s)\n",
        "    ttt1.append(s.lemma_names(lan))\n",
        "\n",
        "ttt1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yIsqQI_K-Po",
        "outputId": "902bb6fe-462b-47de-a216-08382d990bd9"
      },
      "execution_count": 157,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence : \n",
            "Be the change you want to see in the world.\n",
            "Please select an available language code from eng, fra, arb, spa, swe, dan, cmn, tha, and jpn.\n",
            "arb\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['تبْدِيل', 'تعْدِيل', 'تغيُّر', 'تغْيِير'],\n",
              " [],\n",
              " [],\n",
              " ['الخلْق', 'الدُنْيا', 'العالم', 'الكوْن', 'الوُجُود']]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    }
  ]
}